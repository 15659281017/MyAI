一、库文件
    在编写代码的过程中需要用到很多库，但是在Pycharm中下载的话很容易失败，使用命令窗口下载又很繁琐，所以我前几天下载了Anaconda，使用Anaconda来下载需要用到的库。
    使用到的库有：keras、tensorflow、tensorflow-gpu、pillow、numpy、opencv、cv2等。
    下载这些库真的废了很大功夫，查了很多资料，有的库之间还需要版本一致才可以使用，如tensorflow和tensorflow-gpu；而最麻烦的库cv2需要先下载numpy和opencv后才能import成功。

二、数据集
    我在网上下载了一个一共2507张图片的数据集，并已经分为六大类：纸板（cardboard）、玻璃（glass）、金属（metal）、纸（paper）、塑料（plastic）、其他垃圾（trash）。
    并且我把它们六类都划分成了三个部分：训练集（train，共计1278张）、验证集（validation，共计709张）、测试集（test，共计520张）。
    其中训练集和验证集用于机器学习的训练，测试集用于人工输入测试。
    
三、运行过程
    ①先运行train.py来训练机器学习，来生成一个个.h5文件。
    ②然后运行predict.py，将代码:    
        model.load_weights("weights-improvement-05-0.42.h5"); 
      引号中的部分改成最后一次运行后的.h5文件，为了方便测试，这里我设置他的epochs仅为5。
    ③最后运行main.py文件进行测试，将代码：
        detect("dataset/test/glass/glass400.jpg");
      引号中的部分改成先要进行分析测试的图片的路径，就可以得到结果了。
      
四、小结
    在代码的运行中遇到了很多错误，就不一一枚举了。在坚持不懈的调试和团队成员的协助下，终于将代码跑了起来。
    但因为只设置了epochs为5次，所以最后的准确率并不高，导致测试的时候将垃圾的种类分析错误。如“结果分析图.jpg”，我输入了一个glass（玻璃）的图片，但是分析的结果却是trash（其他垃圾）。后续还需继续对代码进行改进，提高识别的准确度。
